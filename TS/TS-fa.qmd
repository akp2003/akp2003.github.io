---
title: "Time Series Models on DOGE Coin Data"
author: "Arshak Parsa"
date: last-modified
code-block-border-left: "#31BAE9"
code-overflow: wrap
engine: knitr
format:
  revealjs:
    css: styles.css
    embed-resources: true
---

```{r}
#| include: false
knitr::opts_chunk$set(echo = TRUE)
```

## هدف این ارائه

قراره مدل های مختلف سری زمانی رو به داده های دوج کوین برازش کنیم!

```{r}
#| warning: false
library(knitr)
library(tseries);library(TSA)
library(broom)
library(rlist)
```

## اینا همش کلاهبرداریه!

![](scam.jpg)

## اینا واقعیه

![Ritvik Kharkar](real.png)

این داداشمون اسمش **ریتویک خارکار** هست که ویدیو های سری زمانی ایشون رو می تونید تو یوتیوب **رایگان** ببینید! یکی دوره های پولسازی **آشغالشو** میلیونی میفروشه از اون طرف یکی دیگه به **رایگان** بهترین مطالب رو به اشتراک میزاره!

## چطور داده دانلود کنیم؟

دستور زیر رو در لینوکس اجرا کنید تا داده ها از نوبیتکس دانلود بشه

```{bash}
#| eval: false
curl 'https://api.nobitex.ir/market/udf/history?
symbol=DOGEIRT&resolution=D&to=1862230967'
-o DOGEIRT-D.json
```

با تغییر resolution و symbol می تونید داده‌های متفاوت بگیرید ، مثلاً symbol=BTCIRT داده بیتکوین میده

زمان ها به فرمت unix time داده می شود!

دستور معادل در R

```{r}
#| eval: false
library(curl)
library(jsonlite)
tmp <- tempfile()
curl_download("https://api.nobitex.ir/market/udf/history?symbol=DOGEIRT&resolution=D&to=1862230967", tmp)
d = as.data.frame.list(fromJSON(jsonlite::prettify(readLines(tmp))))[,-1]
d$t = as.Date.POSIXct(d$t, origin="1970-01-01")
write.csv(d,"DOGEIRT-D.csv",row.names = FALSE)
```

## تبدیل json به csv در پایتون

این کد های پایتون قدیمی هست!

```{python}
#| eval: false
import json
import pandas as pd
file = 'DOGEIRT-D'
with open(file+'.json') as train_file:
    dict1 = json.load(train_file)

# converting json dataset from dictionary to dataframe
df = pd.DataFrame(data=dict1)
df = df.drop('s', axis=1)
df['t'] = pd.to_datetime(df['t'],unit='s')
df = df.set_index('t')
df.index = pd.DatetimeIndex(df.index).to_period('D')
df.to_csv(file+'.csv')
```

اینا کد پایتونه، از اسلاید بعد همه کد ها تو R هست

## بارگذاری داده ها در R

```{r}
d = read.csv("DOGEIRT-D.csv")
d$t = as.Date(d$t)
kable(head(d,2))
kable(tail(d,2))
```

## تبدیل تاریخ به اعداد

```{r}
df = data.frame(time = d$t,c = d$c)
tr.t = as.numeric(df[,1]-df[1,1]+1)
head(df)
```

## رسم داده ها

```{r}
library(plotly)
fig.candles = d %>% plot_ly(x = ~t, type="candlestick",
          open = ~o, close = ~c,
          high = ~h, low = ~l) 
fig.candles
```

## چطور مدل ها را مقایسه کنیم؟

-   ارزیابی بلند مدت

-   ارزیابی کوتاه مدت

## Forecast Accuracy Measures

::: ltr_temp
$P_i$ مقدار پیش بینی شده و $A_i$ مقدار واقعی هست.

$$MSE = \frac{1}{n}\sum_{i=1}^{n}(A_i-P_i)^2$$ $$RMSE = \sqrt{MSE}$$ $$MAD = \frac{1}{n}\sum_{i=1}^{n}|A_i-P_i|$$

فعلا آخرین قیمت closed price را به عنوان متغییر پاسخ در نظر میگیریم.
:::

## یک تابع برای ارزیابی **بلند مدت**

```{r}
library(zeallot)
res_prep = function(pred,lpred,lfun){
  res = matrix(nrow = length(lfun),ncol = length(lpred))
  rownames(res) = names(lfun)
  colnames(res) = names(lpred)
  colnames(pred) = names(lpred)
  for (i in 1:length(lfun)) {
    res[i,] = apply(pred,2,FUN = lfun[[i]])
  }
  return(list(pred = pred, res = res))
}

LTE = function(lpred,data,tname="time",yname="c",percent=0.8) {
  tr = head(data,round(nrow(data)*percent))
  ts = tail(data,nrow(data)-nrow(tr))
  
  extra.info = list()
  pred = matrix(nrow = nrow(ts))
  yind = which(colnames(ts)==yname)
  for (n in names(lpred)){
    lpred.out = lpred[[n]](tr,ts[,-yind,drop=FALSE])
    pred = cbind(pred,lpred.out[["pred"]])
    extra.info[[n]] = lpred.out[["extra.info"]]
  }
  pred = pred[,-1,drop=FALSE]
  
  lfun = list(RMSE=function(x) sqrt(mean((x-ts[,yname])^2)),MAD=function(x) mean(abs(x-ts[,yname])))
  c(pred,res) %<-% res_prep(pred,lpred,lfun)
  
  # Plot 
  fx = as.formula(paste("~",tname))
  fy = as.formula(paste("~",yname))
  fig = plot_ly(mode="lines", type = "scatter")%>%
  add_trace( data=tr, x = fx, y = fy,name = "train")%>%
  add_trace(data=ts, x = fx, y = fy,name = "test")
  
  for (n in colnames(pred))
    fig = fig %>% add_trace(x=ts[,tname],y=pred[,n],name = n)
  return (list(results = res, fig=fig, extra.info = extra.info))
}
```

```{r}
#| include: false
#| eval: false
# This is for test
f.zero = function(tr,ts) numeric(length(ts))
f.one = function(tr,ts) rep(20000,length(ts))
LTE.res = LTE(list(zero=f.zero,one=f.one),df,percent = 0.2)
LTE.res$fig

df.train = head(df,round(nrow(df)*0.8))
df.test = tail(df,nrow(df)-nrow(df.train))
  
```

## ارزیابی کوتاه مدت؟

در اینجا از K-fold Cross Validation نمی‌توان استفاده کرد.

باید از Rolling Cross Validation استفاده کنید که به دو روش sliding و expanding می تونه انجام بشه!

اما ممکنه بپرسید که اصلا Cross Validation چی هست؟!

## **K-fold cross-validation**

![](cs.png)

## **Rolling cross-validation**

![](rc.ppm)

## یک تابع برای ارزیابی **کوتاه مدت**

```{r}
STE = function(lpred,data,tname="time",yname="c",startp=0.97,sliding.time=30,is.plot=TRUE) {
  tr = head(data,round(nrow(data)*startp))
  ts = tail(data,nrow(data)-nrow(tr))
  
  fx = as.formula(paste("~",tname))
  fy = as.formula(paste("~",yname))
  fig.base = plot_ly(mode="lines", type = "scatter")%>%
  add_trace( data=tr, x = fx, y = fy,name = "train")%>%
  add_trace(data=ts, x = fx, y = fy,name = "test")
  
  pred.expand = matrix(nrow = nrow(ts),ncol = length(lpred))
  pred.slide = matrix(nrow = nrow(ts), ncol = length(lpred))
  yind = which(colnames(ts)==yname)
  for (i in 1:nrow(ts)){ 
    for (j in 1:length(lpred)){
      pred.slide[i,j] = lpred[[j]](tail(tr,sliding.time),ts[i,-yind,drop=FALSE])[["pred"]]
      pred.expand[i,j] = lpred[[j]](tr,ts[i,-yind,drop=FALSE])[["pred"]]
    }
    tr = rbind(tr,ts[i,])
  }
  
  lfun = list(RMSE=function(x) sqrt(mean((x-ts[,yname])^2)),MAD=function(x) mean(abs(x-ts[,yname])))
  c(pred.expand,res.expand) %<-% res_prep(pred.expand,lpred,lfun)
  
  c(pred.slide,res.slide) %<-% res_prep(pred.slide,lpred,lfun)
  
  
  # Plot expanding
  fig.ex = fig.base
  fig.sl = fig.base
  
  if(is.plot){
  for (n in colnames(pred.expand))
    fig.ex = fig.ex %>% add_trace(x=ts[,tname],y=pred.expand[,n],name = n)
  
  # Plot sliding
  for (n in colnames(pred.slide))
    fig.sl = fig.sl %>% add_trace(x=ts[,tname],y=pred.slide[,n],name = n)
  }
  
  return(list(expanding=list(res=res.expand,fig=fig.ex), sliding = list(res=res.slide,fig=fig.sl)))
}
```

## یک تابع بدرد بخور

این تابع یکسری پارامتر ها رو می تونه فیکس کنه.

```{r}
f.fix <- function(fname,fixed) {
  variable = c("tr","ts")
  f.new <- function() {}
  formals(f.new) <- setNames(rep(list(bquote()), length(variable)), variable) 

  for(i in variable) assign(i, as.symbol(i))
  body(f.new) <- do.call("call", unlist(list(fname, fixed, mget(variable)),recursive = FALSE))
  
  return(f.new)
}
```

تشکر از [GKI](https://stackoverflow.com/questions/67566677/how-to-create-a-function-that-returns-a-function-with-fixed-parameters-in-r)

## Polynomial Regression

```{r}
m.lm_poly = function(tr,ts,n=2,x=NULL){
  timeInd = which(colnames(tr)=="time")
  t = as.numeric(tr[,1]-tr[1,1]+1)
  ts$t = as.numeric(ts[,1]-tr[1,1]+1)
  tr = tr[,-timeInd,drop=FALSE]
  ts = ts[,-timeInd,drop=FALSE]
  # Note that poly() returns Orthogonal Polynomials 
  if (!is.null(x)){ 
    tr = tr[,c("c",x),drop=FALSE]
    ts = ts[,c("t",x),drop=FALSE]
  }
  if (n==0)
    m = lm(c~.,tr)
  else
    m = lm(c~poly(t,n)+.,tr)
  return(list(pred = predict(m,ts), extra.info = m))
}

poly.list = list(Linear.Reg=f.fix("m.lm_poly",c(n=1)),
                   Poly2.Reg=f.fix("m.lm_poly",c(n=2)),
                   Poly3.Reg=f.fix("m.lm_poly",c(n=3)),
                   Poly4.Reg=f.fix("m.lm_poly",c(n=4)),
                   Poly9.Reg=f.fix("m.lm_poly",c(n=9)) )
              
LTE.poly = LTE(poly.list,df,percent = 0.8)
LTE.poly$results
```

## Polynomial Regression (LTE)

```{r}
LTE.poly$fig
LTE.poly$results
```

## بررسی خروجی lm

```{r}
lm.res = as.data.frame(list.rbind(lapply(LTE.poly$extra.info,glance)))
row.names(lm.res) = names(poly.list)
kable(lm.res)
```

## بررسی خروجی lm

اگر دقت کنید R² برای درجات بالاتر بهتر می شود اما مدل های با درجات بالا در cross validation ضعیف عمل می کنند

(نشانه های بیش برازش ) (over-fitting)

## بررسی خروجی lm

```{r}
summary(LTE.poly$extra.info$Poly4.Reg)
```


## بررسی شرایط مدل

```{r}
par(mfrow=c(2,2));m=LTE.poly$extra.info$Poly4.Reg
plot(m);p=length(m$coefficients);n=nrow(m$model)
abline(h=2);abline(h=-2);abline(v=2*(p+1)/n)
```

## Polynomial Regression (STE)

```{r, ste_pr}
STE.poly = STE(poly.list,df)
STE.poly$expanding$res
STE.poly$sliding$res
```

## Polynomial Regression (STE)

```{r}
STE.poly$expanding$fig
STE.poly$expanding$res
```

## Polynomial Regression (STE)

```{r}
STE.poly$sliding$fig
STE.poly$sliding$res
```

## ایرادات مدل های رگرسیون چند جمله ای

1.  بی بهره از نعمت فراموشی (بی بنفش)
2.  منحنی پیش بینی شده تعداد متنهی قله دارد

## بی بهره از نعمت فراموشی (بی بنفش)

توی این مدل همه داده ها تاثیر یکسانی روی مدل دارند. هرچقدر که این مدل سعی میکنه داده های جدید رو خوب فیت کنه ، همونقدر برای برازش مناسب داده های قدیمی تلاش میکنه! برای همین توی ارزشیابی بلند مدت خیلی خوب عمل نمیکنه!

فراموشی یک نعمت است!

## کتاب فارسی نهم دبیرستان!

![](Pic/farsi.png)

## منحنی پیش بینی شده تعداد متنهی قله دارد

همانطور که می دانید بازار همیشه پستی و بلندی داره! دوره ای نزول میکنه و دوره ای صعود! پس انتظار داریم منحنی پیش بینی شده هم بدون محدودیت ، صعود و نزول کنه و قله هایی رو بسازه. اما یک چند جمله ای درجه n نهایت n-1 قله داره.

## مدل رگرسیون فصلی + مدل رگرسیون چند جمله ای

به اختصار به این مدل ها میگیم SP!

Seasonal Polynomial = SP

قبل از انتخاب تعداد فصل ، بد نیست نگاهی به نمودار ACF بندازیم

```{r}
acf.res = acf(diff(df$c),lag.max = 40)
order(abs(acf.res$acf),decreasing = TRUE)[1:10] -1
```

## L=38

```{r}
df$L38 = factor(rep(1:38,length.out=nrow(df)))
head(df,n = 9)
```

## SP L=38 (LTE)

بیایید L=38 را تست کنیم!

```{r}
LTE.sp38 = LTE(poly.list,df,percent = 0.8)
LTE.sp38$results
```

## SP L=38 (LTE)

```{r}
LTE.sp38$fig
LTE.sp38$results - LTE.poly$results
```


## بررسی خروجی lm

```{r}
lm.res = as.data.frame(list.rbind(lapply(LTE.sp38$extra.info,glance)))
row.names(lm.res) = names(poly.list)
kable(lm.res)
```

## SP L=38 (STE)

```{r, ste_sp_l38}
STE.sp38 = STE(poly.list,df,sliding.time = 38*2)
STE.sp38$expanding$res
STE.sp38$sliding$res
```

## SP L=38 (STE)

```{r}
STE.sp38$expanding$fig
STE.sp38$expanding$res - STE.poly$expanding$res
```

## SP L=38 (STE)

```{r}
STE.sp38$sliding$fig
STE.sp38$sliding$res - STE.poly$sliding$res
```

## ایرادات مدل های SP

1.  بی بهره از نعمت فراموشی (بی بنفش)
2.  مدل اعتماد به نفس نوسان ندارد!

همونطور که دیدید اضافه کردن روند فصلی به مدل **برای این** **داده ها** تاثیری نداشت!

## Polynomial Fourier Series Regression = PF

اول از همه، مدل سری فوریه به صورت زیر هست:

$$
Z_t = \alpha_0 + \sum_{i=1}^q(\alpha_iC_i(t)+\beta_iS_i(t)) + e_t 
$$

به طوری که

$$
S_i(t) = Sin(2\pi f_i t),\space C_i(t) = Cos(2\pi f_i t),\space f_i=i/L
$$

حالا به این چند جمله ای اضافه کنید میشه PF.

## PF

```{r}
fsr.x = c()
for (i in 1:4){
  Sname = paste("S",i,"L38",sep = "")
  Cname = paste("C",i,"L38",sep = "")
  fsr.x = c(fsr.x,Sname,Cname)
  df[,Sname] = sin(2*pi*(i/38)*tr.t)
  df[,Cname] = cos(2*pi*(i/38)*tr.t)
}
head(df)
```

## PF (LTE)

```{r}
pf.list = list(Cubic.H1=f.fix("m.lm_poly",list(n=3,x=fsr.x[1:2])),
                Cubic.H2=f.fix("m.lm_poly",list(n=3,x=fsr.x[1:4])),
                Cubic.H3=f.fix("m.lm_poly",list(n=3,x=fsr.x[1:6])),
                Cubic.H4=f.fix("m.lm_poly",list(n=3,x=fsr.x[1:8]))
                )
LTE.pf = LTE(pf.list,df)
LTE.pf$results
```

## PF (LTE)

```{r}
LTE.pf$fig
LTE.pf$results
```


## بررسی خروجی lm

```{r}
lm.res = as.data.frame(list.rbind(lapply(LTE.pf$extra.info,glance)))
row.names(lm.res) = names(pf.list)
kable(lm.res)
```

## PF (STE)

```{r}
STE.pf = STE(pf.list,df)
STE.pf$expanding$res
STE.pf$sliding$res
```

## PF (STE)

```{r}
STE.pf$expanding$fig
STE.pf$expanding$res

```

## PF (STE)

```{r}
STE.pf$sliding$fig
STE.pf$sliding$res
```

## داده پرت در سری زمانی

![](outliers.png)

## ARIMA

این بخش فعلا آزمایشی است!

```{r}
m.ar = arima(df$c,order = c(1,0,0))
```

## بیایید این داده های پرت را پیدا کنیم!

```{r}
AO = detectAO(m.ar)
IO = detectIO(m.ar)
```


## بیایید این داده های پرت را پیدا کنیم!

```{r}
plot_ly(x = df$time, y = df$c, type = "scatter")%>% add_trace(x=df$time[IO$ind],y=df$c[IO$ind],name="IO") %>% add_trace(x=df$time[AO$ind],y=df$c[AO$ind],name="AO")
```

## پول نداری سرمایه گذاری کنی؟

## برو کار کن!

![](Pic/fb.png)

## برو کار کن!

![](Pic/mofid.png)

## وضعیت جاب ویژن

![](Pic/pishro.webp)

## پول بیشتر می خوای؟

مدل های بهتری میخوای؟

## کتابای بیشتر بخون!

![](books.jpg)

## قراره پولدار بشیم!

![](bro-explaining.jpg)
